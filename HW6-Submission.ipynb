{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 6\n",
    "\n",
    "Nguyễn Ngọc Minh Khánh - 1712525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 1 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo định nghĩa về deterministic noise: là những phần, những mẫu mà tập giả thuyết $\\mathcal H$ không thể bắt được (capture): $f(\\mathbf{x}) − h^∗(\\mathbf{x})$. Trong đó  $h^∗(\\mathbf{x})$ là giả thuyết tốt nhất của $\\mathcal H$ trong việc xấp xỉ hàm target function hay tối thiểu độ lỗi deterministic noise.\n",
    "\n",
    "\n",
    "Vậy như thế nào nếu ta dùng $\\mathcal H^{'}$ thay cho $\\mathcal H$,  với $\\mathcal H^{'} \\subset \\mathcal H $.\n",
    "\n",
    "   - TH1: Nếu $h^∗(\\mathbf{x}) \\in \\mathcal H^{'}$:  Thì độ lỗi deterministic noise không đổi.\n",
    "    \n",
    "   - TH2: Nếu $h^∗(\\mathbf{x}) \\notin \\mathcal H^{'}$:  Thì độ lỗi deterministic noise sẽ tăng, vì lúc này ta sẽ phải chọn ra 1 hàm tốt nhất thuộc $\\mathcal H^{'}$ nhưng lại tệ hơn $h^∗(\\mathbf{x})$ trong việc xấp xỉ target function.\n",
    "   \n",
    "Trong đa số, thì trường hợp 2 xảy ra cao hơn vì khi $\\mathcal H^{'} \\subset \\mathcal H $ thì xác suất để $h^∗(\\mathbf{x}) \\in \\mathcal H^{'}$ là thấp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e83d862b3c5fd4fb57d72c50e8115f8",
     "grade": true,
     "grade_id": "c1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 2 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_transformation(X):\n",
    "    '''\n",
    "    nonlinear transformation: transform X space to Z space :\n",
    "    X(x1, x2) ->  Z(1, L(1, x1, x2, x1^2, x2^2, x1*x2, |x1-x2|, |x1+x2|\n",
    "    \n",
    "    Paramaters:\n",
    "    ----------\n",
    "    X: data before transforming\n",
    "       shape (N, 2)\n",
    "    \n",
    "    return:\n",
    "    X: data after transforming\n",
    "       shape (N, 7)\n",
    "    \n",
    "    '''\n",
    "    N = X.shape[0]\n",
    "    x_d0 = np.ones((N, 1))\n",
    "    x_d1 = X[:, 0].reshape(-1, 1)\n",
    "    x_d2 = X[:, 1].reshape(-1, 1)\n",
    "\n",
    "    x_d3 = x_d1**2\n",
    "    x_d4 = x_d2**2\n",
    "    x_d5 = x_d1*x_d2\n",
    "    x_d6 = abs(x_d1-x_d2)\n",
    "    x_d7 = abs(x_d1+x_d2)\n",
    "    X = np.hstack((x_d0, x_d1, x_d2, x_d3, x_d4, x_d5, x_d6, x_d7))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression_weightDecay:\n",
    "    \"\"\"Linear regression algorithm \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Create a new linear regression algorithm\n",
    "        Args :\n",
    "        trainingSet: is a training data\n",
    "        y : is a label corressponding with training data\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "    def fit(self, trainingSet, y, lamb):\n",
    "        '''\n",
    "        trainingSet: is a training data\n",
    "        y : is a label corressponding with training data\n",
    "        k: is the exponent used in the lambda formula\n",
    "        '''\n",
    "        self.X = trainingSet\n",
    "        self.y = y\n",
    "        self.lamb = lamb\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        w = [(X^T * X)^-1]*(X^T)*y (*)\n",
    "        A = (X^T * X)*X => A^-1 is pseudo-inverse of X\n",
    "        A = A- lambda*I: weight decay = lambda*I with I is identity matrix\n",
    "        b = (X^T)*y\n",
    "        \n",
    "        --> w = A^-1 * b\n",
    "        \"\"\"\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        I = np.eye(X.shape[1]) # create identity matrix\n",
    "        A = X.T@X + self.lamb*I\n",
    "        b = X.T@y\n",
    "        \n",
    "        w = np.dot(np.linalg.inv(A), b)\n",
    "        \n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset():\n",
    "    df_train = np.loadtxt('in.dta.txt')\n",
    "    df_test = np.loadtxt('out.dta.txt')\n",
    "\n",
    "    X_train = nonlinear_transformation(df_train[:, :2])\n",
    "    y_train = df_train[:, 2].reshape(-1, 1)\n",
    "\n",
    "    X_test = nonlinear_transformation(df_test[:, :2])\n",
    "    y_test = df_test[:, 2].reshape(-1, 1)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample classification error: 0.029\n",
      "Out of sample classification error: 0.084\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = dataset()\n",
    "linear = LinearRegression_weightDecay()\n",
    "linear.fit(X_train, y_train, 0)\n",
    "w = linear.run()\n",
    "\n",
    "E_in = np.mean(np.sign(X_train@w)!=y_train)\n",
    "E_out = np.mean(np.sign(X_test@w)!=y_test)\n",
    "\n",
    "print(\"In sample classification error: %0.3f\" %E_in)\n",
    "print(\"Out of sample classification error: %0.3f\" %E_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47d4e2bb3e4812ef7b37e032a898cfec",
     "grade": true,
     "grade_id": "c2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 3 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_k(k):\n",
    "    '''\n",
    "    Paramaters:\n",
    "    k: int\n",
    "    \n",
    "    return: float \n",
    "    '''\n",
    "    return 1.0*(10**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample classification error: 0.029\n",
      "Out of sample classification error: 0.080\n"
     ]
    }
   ],
   "source": [
    "linear.fit(X_train, y_train, lambda_k(-3))\n",
    "w = linear.run()\n",
    "\n",
    "E_in = np.mean(np.sign(X_train@w)!=y_train)\n",
    "E_out = np.mean(np.sign(X_test@w)!=y_test)\n",
    "    \n",
    "print(\"In sample classification error: %0.3f\" %E_in)\n",
    "print(\"Out of sample classification error: %0.3f\" %E_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0997a909d9ab1f250c2bfd0645fee970",
     "grade": true,
     "grade_id": "c3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 4 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample classification error: 0.371\n",
      "Out of sample classification error: 0.436\n"
     ]
    }
   ],
   "source": [
    "linear.fit(X_train, y_train, lambda_k(3))\n",
    "w = linear.run()\n",
    "\n",
    "E_in = np.mean(np.sign(X_train@w)!=y_train)\n",
    "E_out = np.mean(np.sign(X_test@w)!=y_test)\n",
    "    \n",
    "print(\"In sample classification error: %0.3f\" %E_in)\n",
    "print(\"Out of sample classification error: %0.3f\" %E_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "efabab5c4035a6864ac8cb3e0061c6f0",
     "grade": true,
     "grade_id": "c4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 5 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample classification error: 0.200\n",
      "Out of sample classification error with k = 2 is : 0.228\n",
      "In sample classification error: 0.057\n",
      "Out of sample classification error with k = 1 is : 0.124\n",
      "In sample classification error: 0.000\n",
      "Out of sample classification error with k = 0 is : 0.092\n",
      "In sample classification error: 0.029\n",
      "Out of sample classification error with k = -1 is : 0.056\n",
      "In sample classification error: 0.029\n",
      "Out of sample classification error with k = -2 is : 0.084\n"
     ]
    }
   ],
   "source": [
    "lamb = [2, 1, 0, -1, -2]\n",
    "for v in lamb:\n",
    "    linear.fit(X_train, y_train, lambda_k(v))\n",
    "    w = linear.run()\n",
    "    E_out = np.mean(np.sign(X_test@w)!=y_test)\n",
    "    E_in = np.mean(np.sign(X_train@w)!=y_train)\n",
    "    \n",
    "    print(\"In sample classification error: %0.3f\" %E_in)\n",
    "    print(\"Out of sample classification error with k = %d is : %0.3f\" %(v, E_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b484b8390bec96142e8a1213ee8cd2c",
     "grade": true,
     "grade_id": "c5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 6 (1 điểm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-5f3544fe6f8c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-5f3544fe6f8c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    - Với giá trị độ lôĩ ứng với giá trị k=-1 là 0.056\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "- Với giá trị độ lôĩ ứng với giá trị k=-1 là 0.056"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26f542221236fb24d0ddbee584eed7d0",
     "grade": true,
     "grade_id": "c6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 7 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tóm tắt đề bài câu 7:** \n",
    "\n",
    "Ta dùng phép biến đổi `non-linear transformation` $\\Phi$: $\\mathcal X \\in \\mathbb{R} ->  \\mathbf Z \\in \\mathbb{R}^{Q+1}$. Với vector $\\mathbf z$ trong không gian $\\mathbf Z$ gồm các thành phần : $\\mathbf z$ = $( L_0(x) = 1,L_1(x), ... , L_Q(x) )$. Trong đó $L_q(x)$ là một đa thức Legendre bậc q.  \n",
    "\n",
    "Khi đó tập giả thuyết ta có sẽ là tổ hợp tuyến tính của các đa thức Legendre bậc q.\n",
    "\n",
    "$$ \\mathcal H_Q = \\left\\{ \\displaystyle\\sum_{q=0}^{\\mathcal Q} w_q*L_q(x) \\right\\} $$\n",
    "\n",
    "\n",
    "`Với tập giả thuyết trên, đề bài đưa thêm các ràng buộc sau:`\n",
    "        $$ \\mathcal{H}(Q, C, Q_0) = \\left\\{ h\\space|\\space h(x) = \\mathbf w^T\\mathbf z  \\in \\mathcal H_q; w_q = C \\space\\space for \\space\\space q\\geq Q_0 \\right\\} $$\n",
    "        \n",
    "Ý nghĩa của ràng buộc trên là ví dụ: \n",
    "\n",
    "   + $\\mathcal H(10, 0, k) $: thì những đa thức Legendre bậc $q \\geq k $ sẽ ứng với w_q = 0. Tức là sẽ vô hiệu hóa những đa thức đó. Lúc này tập giả thuyết chỉ tương ứng với $\\mathcal H_{k-1}$\n",
    "   + $\\mathcal H(10, 1, k) $: thì những đa thức Legendre bậc $q \\geq k $ sẽ ứng với w_q = 1. Lúc này tập giả thuyết chỉ tương ứng với $\\mathcal H_{k-1}$ + $ \\displaystyle\\sum_{k}^{\\mathcal Q} L_q(x) $\n",
    "\n",
    "\n",
    "`Câu a:` Với $\\mathcal H(10, 0, 3) = \\mathcal H_2$,  $\\mathcal H(10, 0, 4) = \\mathcal H_3$. Lấy phép hợp ta được $\\mathcal H_3$\n",
    "\n",
    "`Câu b:` Với $\\mathcal H(10, 1, 3)$ = $\\left\\{ \\mathcal H_2 +  \\displaystyle\\sum_{3}^{\\mathcal Q} L_q(x) \\right\\}$  và  $\\mathcal H(10, 1, 4) = \\left\\{\\mathcal H_3 +  \\displaystyle\\sum_{4}^{\\mathcal Q} L_q(x) \\right\\} $. Lấy phép hợp ta được  $\\left\\{ \\mathcal H_3 +  \\displaystyle\\sum_{3}^{\\mathcal Q} L_q(x) \\right\\}$.\n",
    "\n",
    "`Câu c:` Với $\\mathcal H(10, 0, 3) = \\mathcal H_2$,  $\\mathcal H(10, 0, 4) = \\mathcal H_3$. Lấy phép giao ta được $\\mathcal H_2$ => Đáp án đúng\n",
    "\n",
    "`Câu d:` Với $\\mathcal H(10, 1, 3)$ = $\\left\\{ \\mathcal H_2 +  \\displaystyle\\sum_{3}^{\\mathcal Q} L_q(x) \\right\\}$  và  $\\mathcal H(10, 1, 4) = \\left\\{\\mathcal H_3 +  \\displaystyle\\sum_{4}^{\\mathcal Q} L_q(x) \\right\\} $. Lấy phép giao ta được  $\\left\\{ \\mathcal H_2 +  \\displaystyle\\sum_{4}^{\\mathcal Q} L_q(x) \\right\\}$.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "322a244b0fae3a20ec568a5099aaaec1",
     "grade": true,
     "grade_id": "c7",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 8 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo đề bài cho, ta có fully connected Neural Network  như hình dưới: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(url='https://drive.google.com/uc?export=download&id=11Vpi3ObB2XSfr_3RXmpyEKFmPGQD1LdS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Số lượng layer là 2 không tính Input layer, $1\\leq l \\leq 2$:\n",
    "   - Input layer:  số neuron là $d^{(0)}$ = 5, không tính neuron $X_0^0$ = 1\n",
    "    \n",
    "   - Hiden layer 1: Số neuron là $d^{(1)}$ = 3, không tính neuron $X_0^1$ =1\n",
    "   \n",
    "   - Output layer: Số neuron là $d^{(2)}$ = 1.\n",
    "   \n",
    "Đề bài hỏi với 1 lần thực hiện Backpropagation với 1 mẫu dữ liệu $\\left(\\mathcal x, \\mathcal y\\right)$ thì sẽ có bao nhiêu phép tính toán. Trong đó 1 phép tính toán có thể rơi vào 3 trường hợp ( tham khảo cách mô tả của thầy ):\n",
    "1. Bắt đầu từ véc-tơ input $\\mathbf{x}$, thực hiện lan truyền tiến qua các tầng của mạng để tính ra các giá trị đầu ra $x$ của các nơ-ron. Ở đây mình dùng ký hiệu $x^{(l)}_i$ để chỉ giá trị đầu ra của nơ-ron $i$ ở tầng $l$. Có bao nhiêu phép tính $w^{(l)}_{ij}x^{(l-1)}_i$ ở bước lan truyền tiến này?\n",
    "2. Từ $\\delta$ ở tầng cuối, thực hiện lan truyền ngược để tính $\\delta$ của các nơ-ron ở các tầng trước đó. Có bao nhiêu phép tính $w^{(l)}_{ij}\\delta^{(l)}_j$ ở bước này? Gợi ý: mục tiêu của việc tính các $\\delta$ là để tính các đạo hàm riêng (ở bước 3), sẽ có một số nơ-ron sẽ không cần tính $\\delta$ vì nếu tính thì không dùng để làm gì cả.\n",
    "3. Với mỗi trọng số $w^{(l)}_{ij}$, tính $\\frac{\\partial e}{\\partial w^{(l)}_{ij}}$ bằng cách lấy $a$ ở một đầu (nơ-ron $i$ ở tầng $l-1$) nhân với $\\delta$ ở đầu kia (nơ-ron $j$ ở tầng $l$). Có bao nhiêu phép tính $a^{(l-1)}_i\\delta^{(l)}_j$ ở bước này?\n",
    "\n",
    "Tính toán các trường hợp:\n",
    "1. Trong bước lan truyền tiến: giá trị $x_i^l$ với $1\\leq i \\leq d^{(l)}$ , $1\\leq l \\leq 2$. Mỗi neuron đều trải qua bước tính tổng có trọng số của tất cả neuron ở layer trước đó. Với $1\\leq l \\leq 2$, nên ta chỉ xét thực hiện lan truyền tiến trên các neuron ở <font color = \"red\"> Hiden layer 1 và Output layer </font>. Điều này là hợp lí vì không có layer nào nằm sau trước <font color = \"red\"> Input layer </font> để thực hiện tính tổng có trọng số. Ứng với các neurons ở <font color = \"red\"> Hidden layer 1</font>: bước tính tổng có trọng số bao gồm 6 phép tính $w^{(l)}_{ij}x^{(l-1)}_i$, và các neurons ở <font color = \"red\"> Output layer </font>: bước tính tổng gồm 4 phép tính $w^{(l)}_{ij}x^{(l-1)}$ ( như hình trên ) => Tổng số phép tính 3\\*6 + 1\\*4 = 22\n",
    "2. Ta không xét các neuron ở <font color = \"red\"> Input layer</font> vì không có trọng số đi kèm. Với <font color = \"red\"> Output layer </font> là layer cuối cùng nên việc tính $\\delta^2_i$ sẽ được tính trực tiếp ( theo như slide 18 lectures 10 ), với i = 1. Vậy chỉ còn phép tính các $\\delta^1_i $ ở <font color = \"red\"> Hiden layer 1 </font>, với $1\\leq i \\leq d^{(1)}$, là cần dùng tới $\\delta^2_1 $( tức neuron duy nhất ở Output layer ): $\\delta^1_i = \\Phi^{'}(s_i^{(1)}) \\space \\mathcal w_{i1}^{(l)} \\space \\delta^2_1 $. Số neuron của <font color = \"red\"> Hiden layer 1 </font> là 3 suy ra số lần xuất hiện của $w_{i1}^{(l)} \\space \\delta^2_1 $ cũng là 3.\n",
    "\n",
    "3. Với mỗi trọng số $w^{(l)}_{ij}$, tính $\\frac{\\partial e}{\\partial w^{(l)}_{ij}}$. Ta có 6 trọng số $\\mathcal w$ ứng với mỗi neuron ở <font color = \"red\"> Hiden layer 1</font> và 4 trọng số ứng với 1 neuron ở <font color = \"red\">Output layer </font>. => ta có 3\\*6+1\\*4 = 22\n",
    "\n",
    "\n",
    "--> `Tổng số phép tính toán là 22 + 3 + 22 = 47`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d81773f072cd15e4a27b6cd240a5d990",
     "grade": true,
     "grade_id": "c8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 9 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo đề bài cho ta có: 10 units ở tầng nhập ( đã tính luôn unit $x_0^{(0)}$ ), 36 hidden units ở các tầng ẩn ( mỗi tầng đã tính luôn $x_0^{(l)}$ như là 1 unit) và 1 unit ở tầng xuất.\n",
    "\n",
    "Ta có 36 hidden units nên sẽ có tối đa là 18 tầng ẩn với mỗi tầng chứa 2 unit. Trong fully connected layer thì mỗi neuron ở tầng l phải liên kiết với tất cả các neuron ở tầng l+1( không tính neuron mang giá trị +1 ), trừ neuron ở tầng xuất.\n",
    "\n",
    "Xét trường hợp đơn giản với 2 hidden unit thuộc về 1 tầng ẩn. Vậy lúc này mạng có tất cả 19 tầng ( layers không tính tầng nhập ). Mạng sẽ có tối đa số cạnh nối giữa các unit thuộc các tầng khác nhau là 46. (*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(url='https://drive.google.com/uc?export=download&id=1LNnGI61od1leECvnn99meXS2jSEBXQXj'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu lúc này ta muốn tầng ẩn bất kì có 3 unit, thì số lượng tầng ẩn sẽ giảm đi 1 và sinh ra 2 tầng ẩn có 3 unit ( không xét trường hợp tầng ẩn 1 cho đơn giản ). Thì ngoài số cạnh nối đã tăng lên. ( dễ hình dung xem hình bên dưới )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(url='https://drive.google.com/uc?export=download&id=1nyStWdHG9Icv0Y3op4f5G-HQrMI4c7O0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e814a2db0b8a53e4fddfee4bcbf405fc",
     "grade": true,
     "grade_id": "c9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án [a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 10 (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với việc tính số trọng số tối đa có trong mạng, ta tiến hành xét mạng có từ một tầng ẩn và tăng dần số tầng ẩn trong mạng:\n",
    "\n",
    "- 1 Tầng ẩn: với mạng có 1 tầng ẩn ta dễ dàng tính được số trọng số là 386\n",
    "- 2 Tần ẩn: với mạng có 2 tầng ẩn ta tìm số lượng trọng số lớn nhất mà mạng có thể đạt được 510. ( theo như code dưới )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer1 = 34\n",
    "hidden_layer2 = 2 # mạng bắt đầu phải có tối thiểu 2 unit\n",
    "max_weights = 0\n",
    "\n",
    "while hidden_layer1>=2:\n",
    "    v = 10*(hidden_layer1-1)+hidden_layer1*(hidden_layer2-1)+hidden_layer2\n",
    "    if max_weights<v:\n",
    "        max_weights = v\n",
    "        exact_hidden_layer1 = hidden_layer1\n",
    "        exact_hidden_layer2 = hidden_layer2\n",
    "    hidden_layer1-=1\n",
    "    hidden_layer2+=1\n",
    "    \n",
    "print('Number of units in hidden layer 1 is ', exact_hidden_layer1)\n",
    "print('Number of units in hidden layer 2 is ', exact_hidden_layer2)\n",
    "print(\"The biggest weights with 2 hidden layers is\", max_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Em không lập trình được tổng quát. Đây là giá trị lớn nhất mà trong số các đáp án có. Và theo em thì số lượng layer tăng đến 1 lượng nào đó thì số lượng trọng số sẽ giảm khi số lượng layer tăng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41cbf5c6d2b94eeae0a712be2181fef6",
     "grade": true,
     "grade_id": "c10",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do đó em chọn đáp án  [e]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
