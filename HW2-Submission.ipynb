{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B√†i t·∫≠p 2\n",
    "\n",
    "H·ªç v√† t√™n: Nguy·ªÖn Ng·ªçc Minh Kh√°nh\n",
    "MSSV: 1712525\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "N = 10 # l√† 1 coin ƒë∆∞·ª£c th·ª±c hi·ªán tung 10 l·∫ßn, ƒë∆∞·ª£c xem nh∆∞ 1 m·∫´u\n",
    "mu = 0.5 # x√°c su·∫•t ƒë∆∞·ª£c m·∫∑t head\n",
    "n_repeats = 100000 # s·ªë l·∫ßn th·ª±c nghi·ªám\n",
    "n_coins = 1000 # s·ªë ƒë·ªìng xu trong 1 l·∫ßn th·ª±c nghi·ªám\n",
    "\n",
    "nus = np.random.binomial(N, mu, (n_repeats, n_coins))/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1 = nus[:, 0]\n",
    "idx = np.random.choice(np.arange(nus.shape[1]), size = nus.shape[0])\n",
    "c_rand = [nus[i, idx[i]] for i in range(n_repeats)]\n",
    "c_rand = np.array(c_rand)\n",
    "c_min = np.min(nus, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 1 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037883999999999994"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min = np.mean(c_min)\n",
    "v_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e83d862b3c5fd4fb57d72c50e8115f8",
     "grade": true,
     "grade_id": "c1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 2 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500134\n",
      "0.49992600000000015\n"
     ]
    }
   ],
   "source": [
    "# Cach 1:\n",
    "v_rand = np.mean(c_rand)\n",
    "v1 = np.mean(c_1)\n",
    "print(v_rand)\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_min thoa bat dang thuc hoeffding:  False\n",
      "c_1 thoa bat dang thuc hoeffding:  True\n",
      "c_rand thoa bat dang thuc hoeffding:  True\n"
     ]
    }
   ],
   "source": [
    "# Cach 2:\n",
    "# Cach 2\n",
    "#import the math module  \n",
    "import math  \n",
    "\n",
    "def VT(c, e, n, mu):\n",
    "    \"\"\"\n",
    "    c: vector ch·ª©a x√°c xu·∫•t l·∫•y ra ƒë∆∞·ª£c m·∫∑t head c·ªßa c√°c l·∫ßn th·ª±c nghi·ªám\n",
    "    e: epsilon\n",
    "    n: s·ªë l·∫ßn th·ª±c nghi·ªám\n",
    "    mu: l√† gi√° tr·ªã x√°c su·∫•t mong ƒë·ª£i c·ªßa x√°c su·∫•t xu·∫•t hi·ªán m·∫∑t head\n",
    "    \"\"\"\n",
    "    return len(c[np.abs(c-mu)>e])/n\n",
    "\n",
    "def VP(e, n):\n",
    "    \"\"\"\n",
    "    e: l√† epsilon\n",
    "    n: s·ªë l·∫ßn th·ª±c nghi·ªám\n",
    "    \"\"\"\n",
    "    return 2*np.exp(-2*n * e**2)\n",
    "\n",
    "def checkHoeffding(c,mu, eps, n):\n",
    "    \"\"\"\n",
    "    # \n",
    "    \"\"\"\n",
    "    for e in eps:\n",
    "        vp = VP(e, n)\n",
    "        \n",
    "        vt = VT(c, e, len(c), mu)\n",
    "\n",
    "        if vt>vp:\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "eps = np.arange(0.01, 0.5, 0.01)    \n",
    "print(\"c_min thoa bat dang thuc hoeffding: \", checkHoeffding(c_min, 0.5, eps, 10))\n",
    "print(\"c_1 thoa bat dang thuc hoeffding: \", checkHoeffding(c_1, 0.5, eps, 10))\n",
    "print(\"c_rand thoa bat dang thuc hoeffding: \", checkHoeffding(c_rand, 0.5, eps, 10))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47d4e2bb3e4812ef7b37e032a898cfec",
     "grade": true,
     "grade_id": "c2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 3 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phi√™n b·∫£n c√≥ t·ªìn t·∫°i noisy c·ªßa h√†m f, x√°c su·∫•t ƒë·ªô l·ªói c·ªßa h trong vi·ªác x·∫•p x·ªâ y x√©t 2 tr∆∞·ªùng h·ª£p l√†:\n",
    "\n",
    "TH1:  ùëÉ(ùë¶=ùëì(ùë•)|ùë•)=ùúÜ , v·ªõi x√°c su·∫•t ƒë·ªô l·ªói l√†  ùúá \n",
    "\n",
    "TH2: ùëÉ(ùë¶‚â†ùëì(ùë•)|ùë•)=1‚àíùúÜ , v·ªõi x√°c su·∫•t d·ª± ƒëo√°n ƒë√∫ng c·ªßa h l√† 1- ùúá  nh∆∞ng l√† tr√™n phi√™n b·∫£n noisy c·ªßa f.\n",
    "\n",
    "x√°c su·∫•t ƒë·ªô l·ªói c·ªßa h trong vi·ªác x·∫•p x·ªâ y l√†:  ùúÜ‚àóùúá+(1‚àíùúÜ)‚àó(1‚àíùúá)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0997a909d9ab1f250c2bfd0645fee970",
     "grade": true,
     "grade_id": "c3",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 4 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C√¢u a) N·∫øu $\\lambda $ =0 th√¨ \\mu mang gi√° tr·ªã cao th√¨ gi·∫£ thuy·∫øt h r·∫•t t·ªá trong vi·ªác x·∫•p x·ªâ f v√† ng∆∞·ª£c l·∫°i.\n",
    "\n",
    "- C√¢u c) N·∫øu $\\lambda =\\frac{1}{\\sqrt{2}}$ th√¨ n·∫øu \\mu mang gi√°t tr·ªã cao th√¨ gi·∫£ thuy·∫øt h r·∫•t t·ªá trong vi·ªác x·∫•p x·ªâ f v√† ng∆∞·ª£c \n",
    "l·∫°i\n",
    "\n",
    "- C√¢u d)N·∫øu $\\lambda$ =1 th√¨ \\mu mang gi√° tr·ªã cao th√¨ gi·∫£ thuy·∫øt h r·∫•t t·ªët trong vi·ªác x·∫•p x·ªâ f v√† ng∆∞·ª£c l·∫°i.\n",
    "\n",
    "--> V·ªõi c√¢u tr·∫£ l·ªùi ·ªü c√¢u 3, ta d·ªÖ d√†ng suy lu·∫≠n ƒë∆∞·ª£c gi√° tr·ªã  ùúÜ  ƒë·ªÉ gi·∫£ thuy·∫øt h kh√¥ng ph·ª• thu·ªôc v√†o  ùúá  l√† 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "efabab5c4035a6864ac8cb3e0061c6f0",
     "grade": true,
     "grade_id": "c4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_w():\n",
    "    \"\"\"\n",
    "    Generates target_w (the vector of parameters of f) \n",
    "    from two random, uniformly distributed points in [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \"\"\"\n",
    "    # Generate two points from a uniform distribution over [-1, 1]x[-1, 1]\n",
    "    p1 = np.random.uniform(-1, 1, 2)\n",
    "    p2 = np.random.uniform(-1, 1, 2)\n",
    "    # Compute the target W from these two points\n",
    "    target_w = np.array([p1[1]*p2[0] - p1[0]*p2[1], p2[1] - p1[1], p1[0] - p2[0]]).reshape((-1, 1))\n",
    "    \n",
    "    return target_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, target_w):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    bad_data = True # `bad_data = True` means: data contain points on the target line \n",
    "                    # (this rarely happens, but just to be careful)\n",
    "                    # -> y's of these points = 0 (with np.sign); \n",
    "                    #    we don't want this (y's of data must be -1 or 1)\n",
    "                    # -> re-generate data until `bad_data = False`\n",
    "    \n",
    "    while bad_data == True:\n",
    "        X = np.random.uniform(-1, 1, (N, 2))\n",
    "        X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "        Y = np.sign(np.dot(X, target_w))\n",
    "        if (0 not in Y): # Good data\n",
    "            bad_data = False\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"Linear regression algorithm \"\"\"\n",
    "    def __init__(self, trainingSet, y):\n",
    "        \"\"\"Create a new linear regression algorithm\n",
    "        Args :\n",
    "        trainingSet: is a training data\n",
    "        y : is a label corressponding with training data\n",
    "        \"\"\"\n",
    "        self.trainingSet = trainingSet\n",
    "        self.y = y\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        w = [(X^T * X)^-1]*(X^T)*y (*)\n",
    "        A = (X^T * X) => A^-1 is pseudo-inverse of X\n",
    "        b = (X^T)*y\n",
    "        \n",
    "        --> w = A^-1 * b\n",
    "        \"\"\"\n",
    "        X = self.trainingSet\n",
    "        y = self.y\n",
    "        \n",
    "        A = np.dot(X.T, X)\n",
    "        b = np.dot(X.T, y)\n",
    "        \n",
    "        w = np.dot(np.linalg.pinv(A), b)\n",
    "        \n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(n_loops = 100, n_points_train = 10, n_points_test=1000):\n",
    "    \n",
    "    avg_test_err_in = 0.0 # The average number of iterations Linear regression takes to converge\n",
    "    avg_test_err_out = 0.0 # The average test error of g - the final hypothesis picked by Linear regression\n",
    "    \n",
    "    for i in range(n_loops):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, Y = generate_data(n_points_train, target_w)\n",
    "        \n",
    "        # Run linear regression to pick g\n",
    "        linear = LinearRegression(X, Y)\n",
    "        w = linear.run()\n",
    "        \n",
    "        #E_in\n",
    "        test_in_err = np.mean(np.sign(np.dot(X, w))!=Y)\n",
    "        #E_out\n",
    "        X_test, Y_test = generate_data(n_points_test, target_w)\n",
    "        test_out_err = np.mean(np.sign(np.dot(X_test, w))!=Y_test)\n",
    "        \n",
    "        # Update average values\n",
    "        avg_test_err_in += (test_in_err*1.0/n_loops)\n",
    "        avg_test_err_out += (test_out_err * 1.0 / n_loops)\n",
    "        \n",
    "     # Print results\n",
    "    print('avg_test_err_in = %f' % (avg_test_err_in))\n",
    "    print('avg_test_err_out = %f' % (avg_test_err_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_test_err_in = 0.039250\n",
      "avg_test_err_out = 0.047008\n"
     ]
    }
   ],
   "source": [
    "run_linear_regression(1000, 100, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 5 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b484b8390bec96142e8a1213ee8cd2c",
     "grade": true,
     "grade_id": "c5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 6 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C√¢u tr·∫£ l·ªùi ·ªü cell th·ª© 16 v·ªõi k·∫øt qu·∫£ avg_test_err_out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26f542221236fb24d0ddbee584eed7d0",
     "grade": true,
     "grade_id": "c6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 7 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_PLA_linear_weight(X, Y):\n",
    "    \"\"\"\n",
    "    Runs PLA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of g.\n",
    "    num_iterations : int\n",
    "        The number of iterations PLA takes to converge.\n",
    "    \"\"\"\n",
    "    linear_regression = LinearRegression(X, Y)\n",
    "    w = linear_regression.run()# Init w with linear regression\n",
    "    \n",
    "    iteration = 0\n",
    "    num_iterations = 10000\n",
    "    for i in range(1, num_iterations):\n",
    "        pred = np.sign(np.dot(X, w))\n",
    "        mis_idx = np.where(np.equal(pred,Y)==False)[0]\n",
    "        \n",
    "        num_mis = mis_idx.shape[0]\n",
    "        \n",
    "        if num_mis==0:\n",
    "            return w, i\n",
    "        \n",
    "        idx = np.random.choice(mis_idx, 1)[0]\n",
    "        w = (w.T + Y[idx]*X[idx, :]).T\n",
    "        i=i+1\n",
    "    print(\"PLA does not converge\")\n",
    "    \n",
    "    return w, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(N): # You don't have to name this function \"main\", you can use other names\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of training examples.\n",
    "    \"\"\"\n",
    "    num_runs = 1000\n",
    "    avg_num_iterations = 0.0 # The average number of iterations PLA takes to converge\n",
    "    avg_test_err = 0.0 # The average test error of g - the final hypothesis picked by PLA\n",
    "\n",
    "    for r in range(num_runs):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, Y = generate_data(N, target_w)\n",
    "        \n",
    "        # Run PLA to pick g\n",
    "        w, num_iterations = run_PLA_linear_weight(X, Y)\n",
    "        \n",
    "        # Generate test set\n",
    "        X_test, Y_test = generate_data(10000, target_w)\n",
    "        \n",
    "        # Test g\n",
    "        test_err = np.mean(np.sign(np.dot(X_test, w)) != Y_test)\n",
    "        \n",
    "        # Update average values\n",
    "        avg_num_iterations += (num_iterations * 1.0 / num_runs)\n",
    "        avg_test_err += (test_err * 1.0 / num_runs)\n",
    "    \n",
    "    # Print results\n",
    "    print('avg_num_iterations = %f' % (avg_num_iterations))\n",
    "    print('avg_test_err = %f' % (avg_test_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 4.807000\n",
      "avg_test_err = 0.104313\n",
      "Total time for running:  0.9566049575805664\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "main(N=10)\n",
    "end_time = time.time()\n",
    "print(\"Total time for running: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "322a244b0fae3a20ec568a5099aaaec1",
     "grade": true,
     "grade_id": "c7",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 8 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy(Y, percent):\n",
    "    \"\"\"\n",
    "    Y: The vector of outputs\n",
    "        numpy array, shape (N, 1)\n",
    "        \n",
    "    percent: percentage of noisy\n",
    "    \n",
    "    \"\"\"\n",
    "    length = Y.shape[0]\n",
    "    num_point = np.int(length*percent/100)\n",
    "    \n",
    "    idx = np.arange(length)\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    for i in range(num_point):\n",
    "        Y[idx[i]] = Y[idx[i]] * -1\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_transform(N, target_w):\n",
    "    bad_data = True # `bad_data = True` means: data contain points on the target line \n",
    "                    # (this rarely happens, but just to be careful)\n",
    "                    # -> y's of these points = 0 (with np.sign); \n",
    "                    #    we don't want this (y's of data must be -1 or 1)\n",
    "                    # -> re-generate data until `bad_data = False`\n",
    "    \n",
    "    while bad_data == True:\n",
    "        X = np.random.uniform(-1, 1, (N, 2))\n",
    "        X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "     \n",
    "        Y = [np.sign(x[1]**2 + x[2]**2 -0.6) for x in X]\n",
    "        Y = np.array(Y)\n",
    "        if (0 not in Y): # Good data\n",
    "            bad_data = False\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_8(n_loops = 100, n_points_train = 10, n_points_test=1000):\n",
    "    \n",
    "    avg_test_err_in = 0.0 # The average number of iterations Linear regression takes to converge\n",
    "    avg_test_err_out = 0.0 # The average test error of g - the final hypothesis picked by Linear regression\n",
    "    \n",
    "    for i in range(n_loops):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, Y = generate_data_transform(n_points_train, target_w)\n",
    "        \n",
    "        #Generate noisy\n",
    "        Y = generate_noisy(Y, 10)\n",
    "        \n",
    "        # Run linear regression to pick g\n",
    "        linear = LinearRegression(X, Y)\n",
    "        w = linear.run()\n",
    "        \n",
    "        #E_in\n",
    "        test_in_err = np.mean(np.sign(np.dot(X, w))!=Y)\n",
    "        #E_out\n",
    "        X_test, Y_test = generate_data_transform(n_points_test, target_w)\n",
    "        test_out_err = np.mean(np.sign(np.dot(X_test, w))!=Y_test)\n",
    "        \n",
    "        # Update average values\n",
    "        avg_test_err_in += (test_in_err*1.0/n_loops)\n",
    "        avg_test_err_out += (test_out_err * 1.0 / n_loops)\n",
    "        \n",
    "     # Print results\n",
    "    print('avg_test_err_in = %f' % (avg_test_err_in))\n",
    "    print('avg_test_err_out = %f' % (avg_test_err_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_test_err_in = 0.502285\n",
      "avg_test_err_out = 0.519960\n"
     ]
    }
   ],
   "source": [
    "run_linear_regression_8(1000, 1000, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d81773f072cd15e4a27b6cd240a5d990",
     "grade": true,
     "grade_id": "c8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 9 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_X(X):\n",
    "    X_transform = [[x[1]*x[2], x[1]**2, x[2]**2] for x in X]\n",
    "    X_transform = np.concatenate((X, X_transform), axis = 1)\n",
    "    return np.array(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_transform_9(N):\n",
    "    bad_data = True # `bad_data = True` means: data contain points on the target line \n",
    "                    # (this rarely happens, but just to be careful)\n",
    "                    # -> y's of these points = 0 (with np.sign); \n",
    "                    #    we don't want this (y's of data must be -1 or 1)\n",
    "                    # -> re-generate data until `bad_data = False`\n",
    "    \n",
    "    while bad_data == True:\n",
    "        X = np.random.uniform(-1, 1, (N, 2))\n",
    "        X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "        X = transform_X(X)\n",
    "        \n",
    "        Y = [np.sign(x[1]**2 + x[2]**2 -0.6) for x in X]\n",
    "        Y = np.array(Y)\n",
    "        if (0 not in Y): # Good data\n",
    "            bad_data = False\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_question_9(n_loops = 100, n_points_train = 10):\n",
    "    arr=[]\n",
    "    for i in range(n_loops):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, Y = generate_data_transform_9(n_points_train)\n",
    "        \n",
    "        #Generate noisy\n",
    "        Y = generate_noisy(Y, 10)\n",
    "        \n",
    "        # Run linear regression to pick g\n",
    "        linear = LinearRegression(X, Y)\n",
    "        w = linear.run()\n",
    "        \n",
    "        # Check hypothesis h\n",
    "        test_h = np.mean(np.sign(np.dot(X, w))!=Y)\n",
    "        # check g1 -> a\n",
    "        w1 = np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5])\n",
    "        test_g1 = np.mean(np.sign(np.dot(X, w1))!=Y)\n",
    "         # check g2 -> b\n",
    "        w1 = np.array([-1, -0.05, 0.08, 0.13, 1.5, 15])\n",
    "        test_g2 = np.mean(np.sign(np.dot(X, w1))!=Y)\n",
    "         # check g3 ->c\n",
    "        w1 = np.array([-1, -0.05, 0.08, 0.13, 15, 1.5])\n",
    "        test_g3 = np.mean(np.sign(np.dot(X, w1))!=Y)\n",
    "         # check g4 ->d\n",
    "        w1 = np.array([-1, -1.5, 0.08, 0.13, 0.05, 0.05])\n",
    "        test_g4 = np.mean(np.sign(np.dot(X, w1))!=Y)\n",
    "         # check g5 ->e\n",
    "        w1 = np.array([-1, -0.05, 0.08, 1.5, 0.15, 0.15])\n",
    "        test_g5 = np.mean(np.sign(np.dot(X, w1))!=Y)\n",
    "        \n",
    "        # 0->a, 1->b, 2->c, 3->d, 4->e\n",
    "        # Xem ƒë·ªô l·ªói c·ªßa h g·∫ßn h√†m g n√†o nh·∫•t\n",
    "        nearest_g = np.argmin(abs([test_g1, test_g2, test_g3, test_g4, test_g5] - test_h))\n",
    "        arr.append(nearest_g)\n",
    "    # Expectation\n",
    "    print(np.mean(arr))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "run_question_9(20, 1000 ) # 0->a, 1->b, 2->c, 3->d, 4->e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e814a2db0b8a53e4fddfee4bcbf405fc",
     "grade": true,
     "grade_id": "c9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn c√¢u [a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√¢u 10 (1 ƒëi·ªÉm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_10(n_loops = 100, n_points_train = 10, n_points_test=1000):\n",
    "    \n",
    "#     avg_test_err_in = 0.0 # The average number of iterations Linear regression takes to converge\n",
    "    avg_test_err_out = 0.0 # The average test error of g - the final hypothesis picked by Linear regression\n",
    "    \n",
    "    for i in range(n_loops):\n",
    "       \n",
    "        # Generate training set\n",
    "        X, Y = generate_data_transform_9(n_points_train)\n",
    "        \n",
    "        #Adding noisy\n",
    "        Y = generate_noisy(Y, 10)\n",
    "        \n",
    "        # Run linear regression to pick g\n",
    "        linear = LinearRegression(X, Y)\n",
    "        w = linear.run()\n",
    "        \n",
    "        #E_in\n",
    "#         test_in_err = np.mean(np.sign(np.dot(X, w))!=Y)\n",
    "        #E_out\n",
    "        X_test, Y_test = generate_data_transform_9(n_points_test)\n",
    "        Y_test  = generate_noisy(Y_test, 10)# ch√∫ √Ω ƒë·ª´ng qu√™n\n",
    "        test_out_err = np.mean(np.sign(np.dot(X_test, w))!=Y_test)\n",
    "        \n",
    "#         # Update average values\n",
    "#         avg_test_err_in += (test_in_err*1.0/n_loops)\n",
    "        avg_test_err_out += (test_out_err * 1.0 / n_loops)\n",
    "        \n",
    "     # Print results\n",
    "#     print('avg_test_err_in = %f' % (avg_test_err_in))\n",
    "    print('avg_test_err_out = %f' % (avg_test_err_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_test_err_out = 0.126122\n"
     ]
    }
   ],
   "source": [
    "run_linear_regression_10(1000, 1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41cbf5c6d2b94eeae0a712be2181fef6",
     "grade": true,
     "grade_id": "c10",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- Do ƒë√≥ em ch·ªçn ƒë√°p √°n [b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
